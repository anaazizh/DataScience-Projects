{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c96c08e-ae78-41e4-8f44-a5aa5adb361b",
   "metadata": {},
   "source": [
    "<h1>Extracting and Visualizing Stock Data</h1>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04819f32-ae3e-4b50-8406-3d3a09f08ac0",
   "metadata": {},
   "source": [
    "\n",
    "<h2>Description</h2>\n",
    "\n",
    "Extracting essential data from a dataset and displaying it is a necessary part of data science allowing stakeholders to make correct decisions based on the data. In this notebook, I will extract some stock data and then display this data in a graph. In this notebook, I will extract some stock data and then display this data in a graph.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc64c522-2d64-44ed-9022-66cb5b614c50",
   "metadata": {},
   "source": [
    "<h2>Objective</h2>\n",
    "\n",
    "My goal is to extract financial data like historical share price and querterly revenue reportings from various sources using python libraries and webscraping on popular stocks. After collecting this data I will visualize it in a dashboard to identify patterns or trends. Stocks I will work with are Tesla and GameStop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7eb5c2e-aedc-4cfc-9f5b-31e39413bb08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: yfinance in c:\\users\\ana02\\anaconda3\\lib\\site-packages (0.2.51)\n",
      "Requirement already satisfied: pandas>=1.3.0 in c:\\users\\ana02\\anaconda3\\lib\\site-packages (from yfinance) (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.16.5 in c:\\users\\ana02\\anaconda3\\lib\\site-packages (from yfinance) (1.26.4)\n",
      "Requirement already satisfied: requests>=2.31 in c:\\users\\ana02\\anaconda3\\lib\\site-packages (from yfinance) (2.32.3)\n",
      "Requirement already satisfied: multitasking>=0.0.7 in c:\\users\\ana02\\anaconda3\\lib\\site-packages (from yfinance) (0.0.11)\n",
      "Requirement already satisfied: lxml>=4.9.1 in c:\\users\\ana02\\anaconda3\\lib\\site-packages (from yfinance) (5.2.1)\n",
      "Requirement already satisfied: platformdirs>=2.0.0 in c:\\users\\ana02\\anaconda3\\lib\\site-packages (from yfinance) (3.10.0)\n",
      "Requirement already satisfied: pytz>=2022.5 in c:\\users\\ana02\\anaconda3\\lib\\site-packages (from yfinance) (2024.1)\n",
      "Requirement already satisfied: frozendict>=2.3.4 in c:\\users\\ana02\\anaconda3\\lib\\site-packages (from yfinance) (2.4.2)\n",
      "Requirement already satisfied: peewee>=3.16.2 in c:\\users\\ana02\\anaconda3\\lib\\site-packages (from yfinance) (3.17.8)\n",
      "Requirement already satisfied: beautifulsoup4>=4.11.1 in c:\\users\\ana02\\anaconda3\\lib\\site-packages (from yfinance) (4.12.3)\n",
      "Requirement already satisfied: html5lib>=1.1 in c:\\users\\ana02\\anaconda3\\lib\\site-packages (from yfinance) (1.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\ana02\\anaconda3\\lib\\site-packages (from beautifulsoup4>=4.11.1->yfinance) (2.5)\n",
      "Requirement already satisfied: six>=1.9 in c:\\users\\ana02\\anaconda3\\lib\\site-packages (from html5lib>=1.1->yfinance) (1.16.0)\n",
      "Requirement already satisfied: webencodings in c:\\users\\ana02\\anaconda3\\lib\\site-packages (from html5lib>=1.1->yfinance) (0.5.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\ana02\\anaconda3\\lib\\site-packages (from pandas>=1.3.0->yfinance) (2.9.0.post0)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\ana02\\anaconda3\\lib\\site-packages (from pandas>=1.3.0->yfinance) (2023.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ana02\\anaconda3\\lib\\site-packages (from requests>=2.31->yfinance) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ana02\\anaconda3\\lib\\site-packages (from requests>=2.31->yfinance) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ana02\\anaconda3\\lib\\site-packages (from requests>=2.31->yfinance) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ana02\\anaconda3\\lib\\site-packages (from requests>=2.31->yfinance) (2024.8.30)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install yfinance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "490ba872-36d1-45ee-94d4-704e824a1229",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac735fa4-f5a5-4f1a-80e0-b40b7400d92a",
   "metadata": {},
   "source": [
    "## Define Graphing Function\n",
    "\n",
    "In this section, I define the function `make_graph`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5fd52421-fb58-4d86-b1f5-822b43ebf3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_graph(stock_data, revenue_data, stock):\n",
    "    fig = make_subplots(rows=2, cols=1, shared_xaxes=True, subplot_titles=(\"Historical Share Price\", \"Historical Revenue\"), vertical_spacing = .3)\n",
    "    fig.add_trace(go.Scatter(x=pd.to_datetime(stock_data.Date, infer_datetime_format=True), y=stock_data.Close.astype(\"float\"), name=\"Share Price\"), row=1, col=1)\n",
    "    fig.add_trace(go.Scatter(x=pd.to_datetime(revenue_data.Date, infer_datetime_format=True), y=revenue_data.Revenue.astype(\"float\"), name=\"Revenue\"), row=2, col=1)\n",
    "    fig.update_xaxes(title_text=\"Date\", row=1, col=1)\n",
    "    fig.update_xaxes(title_text=\"Date\", row=2, col=1)\n",
    "    fig.update_yaxes(title_text=\"Price ($US)\", row=1, col=1)\n",
    "    fig.update_yaxes(title_text=\"Revenue ($US Millions)\", row=2, col=1)\n",
    "    fig.update_layout(showlegend=False,\n",
    "    height=900,\n",
    "    title=stock,\n",
    "    xaxis_rangeslider_visible=True)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e14580-85a9-47e6-864a-509e32ba165e",
   "metadata": {},
   "source": [
    "## Using yfinance to Extract Stock Data\n",
    "\n",
    "Using the `Ticker` function, the ticker symbol of the stock I want to extract data is entered to create a ticker object. The stock is Tesla and its ticker symbol is `TSLA`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae129741-8669-44de-9429-877c9113526b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Tesla = yf.Ticker(\"TSLA\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e9c39b-91b1-4033-ba76-81f2695c2d16",
   "metadata": {},
   "source": [
    "Using the ticker object and the function `history`, I extract stock information and save it in a dataframe named `tesla_data`.  The `period` parameter is set to `max` so I get information for the maximum amount of time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21df3305-f042-42ac-b53e-c93dd45ff55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tesla_data = Tesla.history(period=\"max\")\n",
    "df=tesla_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d8e8eb1-6277-4afb-af83-2bbfe69ceddc",
   "metadata": {},
   "source": [
    "I then reset the index, save, and display the first five rows of the `tesla_data` dataframe using the `head` function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5355b815-051a-40f7-beab-60bf31f6a64a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Dividends</th>\n",
       "      <th>Stock Splits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-06-29 00:00:00-04:00</td>\n",
       "      <td>1.266667</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>1.169333</td>\n",
       "      <td>1.592667</td>\n",
       "      <td>281494500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-06-30 00:00:00-04:00</td>\n",
       "      <td>1.719333</td>\n",
       "      <td>2.028000</td>\n",
       "      <td>1.553333</td>\n",
       "      <td>1.588667</td>\n",
       "      <td>257806500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-07-01 00:00:00-04:00</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>1.728000</td>\n",
       "      <td>1.351333</td>\n",
       "      <td>1.464000</td>\n",
       "      <td>123282000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-07-02 00:00:00-04:00</td>\n",
       "      <td>1.533333</td>\n",
       "      <td>1.540000</td>\n",
       "      <td>1.247333</td>\n",
       "      <td>1.280000</td>\n",
       "      <td>77097000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-07-06 00:00:00-04:00</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>1.055333</td>\n",
       "      <td>1.074000</td>\n",
       "      <td>103003500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Date      Open      High       Low     Close  \\\n",
       "0 2010-06-29 00:00:00-04:00  1.266667  1.666667  1.169333  1.592667   \n",
       "1 2010-06-30 00:00:00-04:00  1.719333  2.028000  1.553333  1.588667   \n",
       "2 2010-07-01 00:00:00-04:00  1.666667  1.728000  1.351333  1.464000   \n",
       "3 2010-07-02 00:00:00-04:00  1.533333  1.540000  1.247333  1.280000   \n",
       "4 2010-07-06 00:00:00-04:00  1.333333  1.333333  1.055333  1.074000   \n",
       "\n",
       "      Volume  Dividends  Stock Splits  \n",
       "0  281494500        0.0           0.0  \n",
       "1  257806500        0.0           0.0  \n",
       "2  123282000        0.0           0.0  \n",
       "3   77097000        0.0           0.0  \n",
       "4  103003500        0.0           0.0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.reset_index(inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45dbad7f-ad82-43f3-8e1e-665708146b17",
   "metadata": {},
   "source": [
    "## Question 2: Use Webscraping to Extract Tesla Revenue Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d265dbc2-d853-44d3-b334-f17e5af21a84",
   "metadata": {},
   "source": [
    "I use the `requests` library to download the webpage [https://www.macrotrends.net/stocks/charts/TSLA/tesla/revenue](https://www.macrotrends.net/stocks/charts/TSLA/tesla/revenue?cm_mmc=Email_Newsletter-_-Developer_Ed%2BTech-_-WW_WW-_-SkillsNetwork-Courses-IBMDeveloperSkillsNetwork-PY0220EN-SkillsNetwork-23455606&cm_mmca1=000026UJ&cm_mmca2=10006555&cm_mmca3=M12345678&cvosrc=email.Newsletter.M12345678&cvo_campaign=000026UJ&cm_mmc=Email_Newsletter-_-Developer_Ed%2BTech-_-WW_WW-_-SkillsNetwork-Courses-IBMDeveloperSkillsNetwork-PY0220EN-SkillsNetwork-23455606&cm_mmca1=000026UJ&cm_mmca2=10006555&cm_mmca3=M12345678&cvosrc=email.Newsletter.M12345678&cvo_campaign=000026UJ&cm_mmc=Email_Newsletter-_-Developer_Ed%2BTech-_-WW_WW-_-SkillsNetwork-Courses-IBMDeveloperSkillsNetwork-PY0220EN-SkillsNetwork-23455606&cm_mmca1=000026UJ&cm_mmca2=10006555&cm_mmca3=M12345678&cvosrc=email.Newsletter.M12345678&cvo_campaign=000026UJ&cm_mmc=Email_Newsletter-_-Developer_Ed%2BTech-_-WW_WW-_-SkillsNetwork-Courses-IBMDeveloperSkillsNetwork-PY0220EN-SkillsNetwork-23455606&cm_mmca1=000026UJ&cm_mmca2=10006555&cm_mmca3=M12345678&cvosrc=email.Newsletter.M12345678&cvo_campaign=000026UJ). Then save the text of the response as a variable named `html_data`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6f72daaf-c65b-44fc-951a-bab72561b6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "url= \"https://www.macrotrends.net/stocks/charts/TSLA/tesla/revenue\"\n",
    "html_data = requests.get(url).text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d48c34f4-9edf-44ef-9309-e6895ca6f783",
   "metadata": {},
   "source": [
    "I Parse the html data using `beautiful_soup`. Then scrape the table on the webpage into a dataframe, it should look like the table from the website.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "099780bc-7dee-4043-8eae-238e67200fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(html_data,\"html.parser\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e7d0486-c20d-4685-aa80-c8b870ba444b",
   "metadata": {},
   "source": [
    "I use beautiful soup extract the table with Tesla Quarterly Revenue and store it into a dataframe named `tesla_revenue`. The comma and dollar sign is removed from the `Revenue` column.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7386dfef-ae31-47ac-aaa9-af7e6a17a633",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ana02\\AppData\\Local\\Temp\\ipykernel_11788\\3212783899.py:1: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  df=pd.read_html(html_data,header=0)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No tables found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df\u001b[38;5;241m=\u001b[39mpd\u001b[38;5;241m.\u001b[39mread_html(html_data,header\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m      2\u001b[0m table\u001b[38;5;241m=\u001b[39msoup\u001b[38;5;241m.\u001b[39mfind_all(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtable\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m second_table\u001b[38;5;241m=\u001b[39m table[\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\html.py:1240\u001b[0m, in \u001b[0;36mread_html\u001b[1;34m(io, match, flavor, header, index_col, skiprows, attrs, parse_dates, thousands, encoding, decimal, converters, na_values, keep_default_na, displayed_only, extract_links, dtype_backend, storage_options)\u001b[0m\n\u001b[0;32m   1224\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(io, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28many\u001b[39m(\n\u001b[0;32m   1225\u001b[0m     [\n\u001b[0;32m   1226\u001b[0m         is_file_like(io),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1230\u001b[0m     ]\n\u001b[0;32m   1231\u001b[0m ):\n\u001b[0;32m   1232\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1233\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPassing literal html to \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mread_html\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is deprecated and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1234\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwill be removed in a future version. To read from a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1237\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m   1238\u001b[0m     )\n\u001b[1;32m-> 1240\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _parse(\n\u001b[0;32m   1241\u001b[0m     flavor\u001b[38;5;241m=\u001b[39mflavor,\n\u001b[0;32m   1242\u001b[0m     io\u001b[38;5;241m=\u001b[39mio,\n\u001b[0;32m   1243\u001b[0m     match\u001b[38;5;241m=\u001b[39mmatch,\n\u001b[0;32m   1244\u001b[0m     header\u001b[38;5;241m=\u001b[39mheader,\n\u001b[0;32m   1245\u001b[0m     index_col\u001b[38;5;241m=\u001b[39mindex_col,\n\u001b[0;32m   1246\u001b[0m     skiprows\u001b[38;5;241m=\u001b[39mskiprows,\n\u001b[0;32m   1247\u001b[0m     parse_dates\u001b[38;5;241m=\u001b[39mparse_dates,\n\u001b[0;32m   1248\u001b[0m     thousands\u001b[38;5;241m=\u001b[39mthousands,\n\u001b[0;32m   1249\u001b[0m     attrs\u001b[38;5;241m=\u001b[39mattrs,\n\u001b[0;32m   1250\u001b[0m     encoding\u001b[38;5;241m=\u001b[39mencoding,\n\u001b[0;32m   1251\u001b[0m     decimal\u001b[38;5;241m=\u001b[39mdecimal,\n\u001b[0;32m   1252\u001b[0m     converters\u001b[38;5;241m=\u001b[39mconverters,\n\u001b[0;32m   1253\u001b[0m     na_values\u001b[38;5;241m=\u001b[39mna_values,\n\u001b[0;32m   1254\u001b[0m     keep_default_na\u001b[38;5;241m=\u001b[39mkeep_default_na,\n\u001b[0;32m   1255\u001b[0m     displayed_only\u001b[38;5;241m=\u001b[39mdisplayed_only,\n\u001b[0;32m   1256\u001b[0m     extract_links\u001b[38;5;241m=\u001b[39mextract_links,\n\u001b[0;32m   1257\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1258\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[0;32m   1259\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\html.py:1003\u001b[0m, in \u001b[0;36m_parse\u001b[1;34m(flavor, io, match, attrs, encoding, displayed_only, extract_links, storage_options, **kwargs)\u001b[0m\n\u001b[0;32m   1001\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1002\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m retained \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# for mypy\u001b[39;00m\n\u001b[1;32m-> 1003\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m retained\n\u001b[0;32m   1005\u001b[0m ret \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m   1006\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m table \u001b[38;5;129;01min\u001b[39;00m tables:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\html.py:983\u001b[0m, in \u001b[0;36m_parse\u001b[1;34m(flavor, io, match, attrs, encoding, displayed_only, extract_links, storage_options, **kwargs)\u001b[0m\n\u001b[0;32m    972\u001b[0m p \u001b[38;5;241m=\u001b[39m parser(\n\u001b[0;32m    973\u001b[0m     io,\n\u001b[0;32m    974\u001b[0m     compiled_match,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    979\u001b[0m     storage_options,\n\u001b[0;32m    980\u001b[0m )\n\u001b[0;32m    982\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 983\u001b[0m     tables \u001b[38;5;241m=\u001b[39m p\u001b[38;5;241m.\u001b[39mparse_tables()\n\u001b[0;32m    984\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m caught:\n\u001b[0;32m    985\u001b[0m     \u001b[38;5;66;03m# if `io` is an io-like object, check if it's seekable\u001b[39;00m\n\u001b[0;32m    986\u001b[0m     \u001b[38;5;66;03m# and try to rewind it before trying the next parser\u001b[39;00m\n\u001b[0;32m    987\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(io, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseekable\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m io\u001b[38;5;241m.\u001b[39mseekable():\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\html.py:249\u001b[0m, in \u001b[0;36m_HtmlFrameParser.parse_tables\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    241\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparse_tables\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    242\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    243\u001b[0m \u001b[38;5;124;03m    Parse and return all tables from the DOM.\u001b[39;00m\n\u001b[0;32m    244\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    247\u001b[0m \u001b[38;5;124;03m    list of parsed (header, body, footer) tuples from tables.\u001b[39;00m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 249\u001b[0m     tables \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parse_tables(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_doc(), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmatch, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattrs)\n\u001b[0;32m    250\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parse_thead_tbody_tfoot(table) \u001b[38;5;28;01mfor\u001b[39;00m table \u001b[38;5;129;01min\u001b[39;00m tables)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\html.py:598\u001b[0m, in \u001b[0;36m_BeautifulSoupHtml5LibFrameParser._parse_tables\u001b[1;34m(self, document, match, attrs)\u001b[0m\n\u001b[0;32m    596\u001b[0m tables \u001b[38;5;241m=\u001b[39m document\u001b[38;5;241m.\u001b[39mfind_all(element_name, attrs\u001b[38;5;241m=\u001b[39mattrs)\n\u001b[0;32m    597\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tables:\n\u001b[1;32m--> 598\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo tables found\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    600\u001b[0m result \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    601\u001b[0m unique_tables \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[1;31mValueError\u001b[0m: No tables found"
     ]
    }
   ],
   "source": [
    "df=pd.read_html(html_data,header=0)\n",
    "table=soup.find_all('table')\n",
    "second_table= table[1]\n",
    "tesla_revenue= pd.DataFrame(columns=[\"Date\",\"Revenue\"])\n",
    "for row in second_table.find(\"tbody\").find_all(\"tr\"):\n",
    "    col= row.find_all('td')\n",
    "    date= col[0].string\n",
    "    revenue= col[1].string\n",
    "    tesla_revenue= tesla_revenue.append({\"Date\":date, \"Revenue\":revenue}, ignore_index = True)\n",
    "tesla_revenue[\"Revenue\"]= tesla_revenue['Revenue'].str.replace('$','').str.replace(',','')\n",
    "print(tesla_revenue)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "898b416f-8461-448b-b383-cd6eb0437b18",
   "metadata": {},
   "source": [
    "I remove the columns in the dataframe that are empty strings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "adf26984-52c1-4deb-825d-de42f8201d82",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tesla_revenue' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m tesla_revenue\u001b[38;5;241m.\u001b[39mdropna(subset\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRevenue\u001b[39m\u001b[38;5;124m'\u001b[39m], inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tesla_revenue : tesla_revenue[i] \u001b[38;5;241m=\u001b[39m tesla_revenue[i]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mstr\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tesla_revenue' is not defined"
     ]
    }
   ],
   "source": [
    "tesla_revenue.dropna(subset=['Revenue'], inplace=True)\n",
    "for i in tesla_revenue : tesla_revenue[i] = tesla_revenue[i].astype(str)\n",
    "#tesla_revenue['Date'] = tesla_revenue['Date'].astype(str)\n",
    "#tesla_revenue['Revenue'] = tesla_revenue['Revenue'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50173c7f-7a61-41e9-89ac-86fed9c5e86b",
   "metadata": {},
   "source": [
    "I display the last 5 row of the `tesla_revenue` dataframe using the `tail` function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aab163e0-883d-45ee-a9de-1f5252b932ab",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tesla_revenue' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m tesla_revenue\u001b[38;5;241m.\u001b[39mtail(\u001b[38;5;241m5\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tesla_revenue' is not defined"
     ]
    }
   ],
   "source": [
    "tesla_revenue.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b35fde3-71d2-4fd0-bcdf-afd09b12f307",
   "metadata": {},
   "source": [
    "## Using yfinance to Extract Stock Data pt.2\n",
    "\n",
    "Using the `Ticker` function, I enter the ticker symbol of the stock I want to extract data on to create a ticker object. The stock is GameStop and its ticker symbol is `GME`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ecb77163-2b1a-4a86-a4a8-1d68f6e1460e",
   "metadata": {},
   "outputs": [],
   "source": [
    "GME= yf.Ticker(\"GME\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c071e712-c95e-4514-bd2d-897b845fe7ca",
   "metadata": {},
   "source": [
    "Using the ticker object and the function `history`, I extract stock information and save it in a dataframe named `gme_data`. I then set the `period` parameter to `max` so I get information for the maximum amount of time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "da4cda9d-fb1c-411a-9d2a-ee1e393d079d",
   "metadata": {},
   "outputs": [],
   "source": [
    "GME_share_price_data = GME.history(period=\"max\")\n",
    "df=GME_share_price_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b97809c8-206a-4775-8bf9-2e747ab5cdce",
   "metadata": {},
   "source": [
    "I reset the index, save, and display the first five rows of the `gme_data` dataframe using the `head` function. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "803cc47e-8dcb-4b17-8789-f9b770ebec24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Dividends</th>\n",
       "      <th>Stock Splits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2002-02-13 00:00:00-05:00</td>\n",
       "      <td>1.620128</td>\n",
       "      <td>1.693350</td>\n",
       "      <td>1.603296</td>\n",
       "      <td>1.691666</td>\n",
       "      <td>76216000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2002-02-14 00:00:00-05:00</td>\n",
       "      <td>1.712708</td>\n",
       "      <td>1.716074</td>\n",
       "      <td>1.670626</td>\n",
       "      <td>1.683251</td>\n",
       "      <td>11021600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2002-02-15 00:00:00-05:00</td>\n",
       "      <td>1.683251</td>\n",
       "      <td>1.687459</td>\n",
       "      <td>1.658002</td>\n",
       "      <td>1.674834</td>\n",
       "      <td>8389600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2002-02-19 00:00:00-05:00</td>\n",
       "      <td>1.666418</td>\n",
       "      <td>1.666418</td>\n",
       "      <td>1.578047</td>\n",
       "      <td>1.607504</td>\n",
       "      <td>7410400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2002-02-20 00:00:00-05:00</td>\n",
       "      <td>1.615920</td>\n",
       "      <td>1.662210</td>\n",
       "      <td>1.603296</td>\n",
       "      <td>1.662210</td>\n",
       "      <td>6892800</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Date      Open      High       Low     Close    Volume  \\\n",
       "0 2002-02-13 00:00:00-05:00  1.620128  1.693350  1.603296  1.691666  76216000   \n",
       "1 2002-02-14 00:00:00-05:00  1.712708  1.716074  1.670626  1.683251  11021600   \n",
       "2 2002-02-15 00:00:00-05:00  1.683251  1.687459  1.658002  1.674834   8389600   \n",
       "3 2002-02-19 00:00:00-05:00  1.666418  1.666418  1.578047  1.607504   7410400   \n",
       "4 2002-02-20 00:00:00-05:00  1.615920  1.662210  1.603296  1.662210   6892800   \n",
       "\n",
       "   Dividends  Stock Splits  \n",
       "0        0.0           0.0  \n",
       "1        0.0           0.0  \n",
       "2        0.0           0.0  \n",
       "3        0.0           0.0  \n",
       "4        0.0           0.0  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.reset_index(inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "675cbd93-19d0-4cd2-8cd9-e2873f7d26c6",
   "metadata": {},
   "source": [
    "## Using Webscraping to Extract GME Revenue Data\n",
    "\n",
    "I use the `requests` library to download the webpage [https://www.macrotrends.net/stocks/charts/GME/gamestop/revenue](https://www.macrotrends.net/stocks/charts/GME/gamestop/revenue?cm_mmc=Email_Newsletter-_-Developer_Ed%2BTech-_-WW_WW-_-SkillsNetwork-Courses-IBMDeveloperSkillsNetwork-PY0220EN-SkillsNetwork-23455606&cm_mmca1=000026UJ&cm_mmca2=10006555&cm_mmca3=M12345678&cvosrc=email.Newsletter.M12345678&cvo_campaign=000026UJ&cm_mmc=Email_Newsletter-_-Developer_Ed%2BTech-_-WW_WW-_-SkillsNetwork-Courses-IBMDeveloperSkillsNetwork-PY0220EN-SkillsNetwork-23455606&cm_mmca1=000026UJ&cm_mmca2=10006555&cm_mmca3=M12345678&cvosrc=email.Newsletter.M12345678&cvo_campaign=000026UJ&cm_mmc=Email_Newsletter-_-Developer_Ed%2BTech-_-WW_WW-_-SkillsNetwork-Courses-IBMDeveloperSkillsNetwork-PY0220EN-SkillsNetwork-23455606&cm_mmca1=000026UJ&cm_mmca2=10006555&cm_mmca3=M12345678&cvosrc=email.Newsletter.M12345678&cvo_campaign=000026UJ&cm_mmc=Email_Newsletter-_-Developer_Ed%2BTech-_-WW_WW-_-SkillsNetwork-Courses-IBMDeveloperSkillsNetwork-PY0220EN-SkillsNetwork-23455606&cm_mmca1=000026UJ&cm_mmca2=10006555&cm_mmca3=M12345678&cvosrc=email.Newsletter.M12345678&cvo_campaign=000026UJ). Then I save the text of the response as a variable named `html_data`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "905dd9ac-9a06-4c74-b06a-1d0e1387a1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "url= \"https://www.macrotrends.net/stocks/charts/GME/gamestop/revenue\"\n",
    "html_data = requests.get(url).text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a1ccc5-c49c-46c3-9452-1b3b16192171",
   "metadata": {},
   "source": [
    "I parse the html data using `beautiful_soup`and scrape the table on the webpage into a dataframe. It should look like the table from the website.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fd0539d9-8931-42ab-9bdc-5fe128123096",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(html_data,\"html.parser\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19793bb-1d06-4e4f-a997-0b7e42b89c56",
   "metadata": {},
   "source": [
    "Using beautiful soup, I extract the table with Tesla Quarterly Revenue and store it into a dataframe named `gme_revenue`.  I make sure the comma and dollar sign is removed from the `Revenue` column.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d2007602-041e-4fe2-9f7e-eb7ca52dc172",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ana02\\AppData\\Local\\Temp\\ipykernel_11788\\3174127543.py:1: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  df=pd.read_html(html_data,header=0)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No tables found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df\u001b[38;5;241m=\u001b[39mpd\u001b[38;5;241m.\u001b[39mread_html(html_data,header\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m      2\u001b[0m table\u001b[38;5;241m=\u001b[39msoup\u001b[38;5;241m.\u001b[39mfind_all(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtable\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m second_table\u001b[38;5;241m=\u001b[39m table[\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\html.py:1240\u001b[0m, in \u001b[0;36mread_html\u001b[1;34m(io, match, flavor, header, index_col, skiprows, attrs, parse_dates, thousands, encoding, decimal, converters, na_values, keep_default_na, displayed_only, extract_links, dtype_backend, storage_options)\u001b[0m\n\u001b[0;32m   1224\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(io, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28many\u001b[39m(\n\u001b[0;32m   1225\u001b[0m     [\n\u001b[0;32m   1226\u001b[0m         is_file_like(io),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1230\u001b[0m     ]\n\u001b[0;32m   1231\u001b[0m ):\n\u001b[0;32m   1232\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1233\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPassing literal html to \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mread_html\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is deprecated and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1234\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwill be removed in a future version. To read from a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1237\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m   1238\u001b[0m     )\n\u001b[1;32m-> 1240\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _parse(\n\u001b[0;32m   1241\u001b[0m     flavor\u001b[38;5;241m=\u001b[39mflavor,\n\u001b[0;32m   1242\u001b[0m     io\u001b[38;5;241m=\u001b[39mio,\n\u001b[0;32m   1243\u001b[0m     match\u001b[38;5;241m=\u001b[39mmatch,\n\u001b[0;32m   1244\u001b[0m     header\u001b[38;5;241m=\u001b[39mheader,\n\u001b[0;32m   1245\u001b[0m     index_col\u001b[38;5;241m=\u001b[39mindex_col,\n\u001b[0;32m   1246\u001b[0m     skiprows\u001b[38;5;241m=\u001b[39mskiprows,\n\u001b[0;32m   1247\u001b[0m     parse_dates\u001b[38;5;241m=\u001b[39mparse_dates,\n\u001b[0;32m   1248\u001b[0m     thousands\u001b[38;5;241m=\u001b[39mthousands,\n\u001b[0;32m   1249\u001b[0m     attrs\u001b[38;5;241m=\u001b[39mattrs,\n\u001b[0;32m   1250\u001b[0m     encoding\u001b[38;5;241m=\u001b[39mencoding,\n\u001b[0;32m   1251\u001b[0m     decimal\u001b[38;5;241m=\u001b[39mdecimal,\n\u001b[0;32m   1252\u001b[0m     converters\u001b[38;5;241m=\u001b[39mconverters,\n\u001b[0;32m   1253\u001b[0m     na_values\u001b[38;5;241m=\u001b[39mna_values,\n\u001b[0;32m   1254\u001b[0m     keep_default_na\u001b[38;5;241m=\u001b[39mkeep_default_na,\n\u001b[0;32m   1255\u001b[0m     displayed_only\u001b[38;5;241m=\u001b[39mdisplayed_only,\n\u001b[0;32m   1256\u001b[0m     extract_links\u001b[38;5;241m=\u001b[39mextract_links,\n\u001b[0;32m   1257\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1258\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[0;32m   1259\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\html.py:1003\u001b[0m, in \u001b[0;36m_parse\u001b[1;34m(flavor, io, match, attrs, encoding, displayed_only, extract_links, storage_options, **kwargs)\u001b[0m\n\u001b[0;32m   1001\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1002\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m retained \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# for mypy\u001b[39;00m\n\u001b[1;32m-> 1003\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m retained\n\u001b[0;32m   1005\u001b[0m ret \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m   1006\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m table \u001b[38;5;129;01min\u001b[39;00m tables:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\html.py:983\u001b[0m, in \u001b[0;36m_parse\u001b[1;34m(flavor, io, match, attrs, encoding, displayed_only, extract_links, storage_options, **kwargs)\u001b[0m\n\u001b[0;32m    972\u001b[0m p \u001b[38;5;241m=\u001b[39m parser(\n\u001b[0;32m    973\u001b[0m     io,\n\u001b[0;32m    974\u001b[0m     compiled_match,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    979\u001b[0m     storage_options,\n\u001b[0;32m    980\u001b[0m )\n\u001b[0;32m    982\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 983\u001b[0m     tables \u001b[38;5;241m=\u001b[39m p\u001b[38;5;241m.\u001b[39mparse_tables()\n\u001b[0;32m    984\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m caught:\n\u001b[0;32m    985\u001b[0m     \u001b[38;5;66;03m# if `io` is an io-like object, check if it's seekable\u001b[39;00m\n\u001b[0;32m    986\u001b[0m     \u001b[38;5;66;03m# and try to rewind it before trying the next parser\u001b[39;00m\n\u001b[0;32m    987\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(io, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseekable\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m io\u001b[38;5;241m.\u001b[39mseekable():\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\html.py:249\u001b[0m, in \u001b[0;36m_HtmlFrameParser.parse_tables\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    241\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparse_tables\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    242\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    243\u001b[0m \u001b[38;5;124;03m    Parse and return all tables from the DOM.\u001b[39;00m\n\u001b[0;32m    244\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    247\u001b[0m \u001b[38;5;124;03m    list of parsed (header, body, footer) tuples from tables.\u001b[39;00m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 249\u001b[0m     tables \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parse_tables(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_doc(), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmatch, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattrs)\n\u001b[0;32m    250\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parse_thead_tbody_tfoot(table) \u001b[38;5;28;01mfor\u001b[39;00m table \u001b[38;5;129;01min\u001b[39;00m tables)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\html.py:598\u001b[0m, in \u001b[0;36m_BeautifulSoupHtml5LibFrameParser._parse_tables\u001b[1;34m(self, document, match, attrs)\u001b[0m\n\u001b[0;32m    596\u001b[0m tables \u001b[38;5;241m=\u001b[39m document\u001b[38;5;241m.\u001b[39mfind_all(element_name, attrs\u001b[38;5;241m=\u001b[39mattrs)\n\u001b[0;32m    597\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tables:\n\u001b[1;32m--> 598\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo tables found\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    600\u001b[0m result \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    601\u001b[0m unique_tables \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[1;31mValueError\u001b[0m: No tables found"
     ]
    }
   ],
   "source": [
    "df=pd.read_html(html_data,header=0)\n",
    "table=soup.find_all('table')\n",
    "second_table= table[1]\n",
    "gme_revenue= pd.DataFrame(columns=[\"Date\",\"Revenue\"])\n",
    "for row in second_table.find(\"tbody\").find_all(\"tr\"):\n",
    "    col= row.find_all('td')\n",
    "    date= col[0].string\n",
    "    revenue= col[1].string\n",
    "    gme_revenue= gme_revenue.append({\"Date\":date, \"Revenue\":revenue}, ignore_index = True)\n",
    "gme_revenue[\"Revenue\"]= gme_revenue['Revenue'].str.replace('$','').str.replace(',','')\n",
    "\n",
    "gme_revenue.dropna(subset=['Revenue'], inplace=True)\n",
    "for i in gme_revenue : gme_revenue[i] = gme_revenue[i].astype(str)\n",
    "print(gme_revenue)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a32b48-e333-4660-aa7c-c87d4881466e",
   "metadata": {},
   "source": [
    "I display the last five rows of the `gme_revenue` dataframe using the `tail` function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "88e8c673-0889-494e-a5c4-6fff29f3a79a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gme_revenue' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m gme_revenue\u001b[38;5;241m.\u001b[39mtail()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'gme_revenue' is not defined"
     ]
    }
   ],
   "source": [
    "gme_revenue.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b66ffe1-816a-42a1-b386-7885b474e7d2",
   "metadata": {},
   "source": [
    "## Plotting Tesla Stock Graph\n",
    "\n",
    "I use the `make_graph` function to graph the Tesla Stock Data, also provide a title for the graph.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "051b4f3f-cf95-4245-b0a6-83ad0871ec9d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tesla_revenue' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m make_graph(tesla_data,tesla_revenue,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTesla Stock Data\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tesla_revenue' is not defined"
     ]
    }
   ],
   "source": [
    "make_graph(tesla_data,tesla_revenue,\"Tesla Stock Data\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f9a63e4-9c6e-479a-89be-18998310c3f5",
   "metadata": {},
   "source": [
    "## Plotting GameStop Stock Graph\n",
    "\n",
    "I use the `make_graph` function to graph the GameStop Stock Data and give the graph a title.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "743b163d-fb1d-4023-8685-73b22abbc321",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gme_revenue' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m make_graph(GME_share_price_data,gme_revenue,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGameStop Stock Data\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'gme_revenue' is not defined"
     ]
    }
   ],
   "source": [
    "make_graph(GME_share_price_data,gme_revenue,\"GameStop Stock Data\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
